name: "Nightly Scope-Replace - Scraper -> Upload (city-by-city) -> Optional Sitemap/Deploy"

on:
  push:
    branches: [ main ]
  schedule:
    # Run once daily at 07:30 UTC (~1:30 AM Central Standard Time; ~2:30 AM during Daylight Time)
    - cron: "30 7 * * *"
  workflow_dispatch:

jobs:
  scrape-upload:
    runs-on: ubuntu-latest
    env:
      # Show timestamps in logs as Central; does not affect scheduling
      TZ: "America/Chicago"

      # CI flag so the scraper knows it's running in automation
      CI: "true"

      # Supabase
      NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
      NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      SUPABASE_TABLE: businesses

      # --- PIN controls ---
      PIN_ENABLE: "true"
      PIN_FORCE_TOP_CITIES: "Franklin,Brentwood"
      PIN_NAME: "HANDYMAN-TN LLC"
      PIN_WEBSITE: "https://www.handyman-tn.com"
      PIN_MAPS_URL: ""
      PIN_PHONE: ""
      PIN_ADDRESS: ""

      # --- Optional small-batch controls (set as repo SECRETS when you want a tiny run) ---
      CITY_SAMPLE: ${{ secrets.CITY_SAMPLE }}   # e.g. "Blountville,Kingsport"
      SERVICES:    ${{ secrets.SERVICES }}      # e.g. ["handyman","tv mounting"]

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Sanity check — Supabase service key present?
        shell: bash
        run: |
          if [ -z "${SUPABASE_SERVICE_ROLE_KEY}" ]; then
            echo "Missing SUPABASE_SERVICE_ROLE_KEY secret. Failing early."
            exit 1
          fi
          echo "Service key present."

      # ---------- Python + Playwright (scraper) ----------
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt

      - name: Install Playwright Chromium (and OS deps)
        run: |
          python -m playwright install --with-deps chromium

      # ---------- Nightly (or tiny) scope-replace ----------
      - name: Run scraper city-by-city with upload (scope-replace)
        shell: bash
        run: |
          python - <<'PY'
          import json, subprocess, sys, os
          from subprocess import TimeoutExpired

          # Build the city list:
          city_sample = (os.environ.get('CITY_SAMPLE') or '').strip()
          if city_sample:
              order = [c.strip() for c in city_sample.split(',') if c.strip()]
          else:
              with open('scraper/cities_seed.json','r',encoding='utf-8') as f:
                  metros = json.load(f)
              seen = set(); order = []
              for m in metros:
                  targets = [{"name": m["city"]}] + m.get("targets", [])
                  for t in targets:
                      name = t["name"]
                      if name not in seen:
                          seen.add(name); order.append(name)

          print(f"[PLAN] {len(order)} cities -> " + ", ".join(order), flush=True)

          CITY_TIMEOUT = 900
          failures = []
          for city in order:
              print(f"\n===== CITY: {city} =====", flush=True)
              try:
                  r = subprocess.run(
                      ['python','scraper/scraper.py','--only-city',city,'--with-upload'],
                      check=False,
                      timeout=CITY_TIMEOUT
                  )
                  if r.returncode != 0:
                      failures.append((city, f"exit={r.returncode}"))
                      print(f"[WARN] City failed: {city} (exit={r.returncode})", flush=True)
              except TimeoutExpired:
                  failures.append((city, "timeout"))
                  print(f"[WARN] City timed out after {CITY_TIMEOUT}s: {city}", flush=True)

          summary_path = os.environ.get('GITHUB_STEP_SUMMARY')
          lines = []
          lines.append(f"### Nightly scrape summary")
          lines.append(f"- Total cities planned: **{len(order)}**")
          lines.append(f"- Failures: **{len(failures)}**")
          if failures:
              lines.append("")
              lines.append("| City | Reason |")
              lines.append("|------|--------|")
              for city, reason in failures:
                  lines.append(f"| {city} | {reason} |")

          if summary_path and os.path.exists(os.path.dirname(summary_path)):
              with open(summary_path, "a", encoding="utf-8") as fh:
                  fh.write("\n".join(lines) + "\n")
          else:
              print("\n".join(lines), flush=True)

          sys.exit(0)
          PY

      - name: Upload exports as artifact
        uses: actions/upload-artifact@v4
        with:
          name: scraper-exports-${{ github.run_id }}
          path: scraper/exports/*.json

      # ---------- Optional: Node (for sitemap) ----------
      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Regenerate sitemap (optional)
        shell: bash
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
        run: |
          if [ -f package.json ]; then
            npm ci || npm install
            npm run sitemap || echo "sitemap step skipped"
          else
            echo "no package.json; skipping sitemap step"
          fi

      - name: Check Vercel secrets
        id: vercel_check
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_PROJECT_SLUG: ${{ secrets.VERCEL_PROJECT_SLUG }}
        shell: bash
        run: |
          if [[ -n "${VERCEL_TOKEN}" && -n "${VERCEL_PROJECT_SLUG}" ]]; then
            echo "should_deploy=true" >> "$GITHUB_OUTPUT"
            echo "Vercel deploy: ENABLED"
          else
            echo "should_deploy=false" >> "$GITHUB_OUTPUT"
            echo "Vercel deploy: DISABLED (missing secrets)"
          fi

      - name: Trigger Vercel Deploy (optional)
        if: steps.vercel_check.outputs.should_deploy == 'true'
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_PROJECT_SLUG: ${{ secrets.VERCEL_PROJECT_SLUG }}
        run: |
          curl -fsS -X POST "https://api.vercel.com/v13/deployments" \
            -H "Authorization: Bearer ${VERCEL_TOKEN}" \
            -H "Content-Type: application/json" \
            --data-raw "{\"name\":\"${VERCEL_PROJECT_SLUG}\",\"project\":\"${VERCEL_PROJECT_SLUG}\"}" \
          || echo "Vercel trigger failed (non-blocking)."
